<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width">
    <title>Canvas &ldquo;clear taint&rdquo; permission</title>
    <link rel="stylesheet" href="../../../archived.css" />
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
  </head>
  
  <body>
    <header class="header">
      <div class="title-span">
        <a href="../../../">
          <img src="../../../images/site-logo.png" height="66" alt="WICG" id="site-logo" />
        </a>
      </div>
    </header>

    <div class="main">
    <div class="archive-span">A partial archive of discourse.wicg.io as of Thursday February 08, 2024.</div>
    <h1 class="topic-title">Canvas &ldquo;clear taint&rdquo; permission</h1>
            <div class="post_container">
        <div class="avatar_container">
          <img src="../../../images/2501_2.png" class="avatar" />
        </div>
        <div class="post">
          <div class="user_name">stuartpb</div>
          <div class="creation_date">2015-08-07</div>
          <div class="post_content">
<p>This is a crazy idea I just had, in the same vein of “allowing pages to request permissions for things that are currently globally-disallowed” as <a href="//discourse.wicg.io/t/api-for-requesting-explicit-permission-to-ignore-security-policies/710/6">API for requesting explicit permission to ignore security policies</a> - allow pages to request, via the notification bar, permission to access an image (displayed by the UA after the user clicks “Show Me” on the notification), clearing the canvas’s taint. (This mechanism of asking for user permission to give a site access to a permission could make many canvas-based operations, like element capture, which have previously been thumbs-downed over security concerns, newly viable.)</p>
<p>Now, of course, the biggest vulnerability here is that <em>the user does not necessarily know what qualifies as sensitive information</em> - a page could display an image that’s 99.9999% fuzzy kitten, and 0.0001% steganographically-hidden margin of an element that reveals the text-wrapping behavior of an account balance that discloses how many digits it contains. However, I believe the solution to that is <a href="//discourse.wicg.io/t/suspicion-based-counter-fingerprinting/655">suspicion-based counter-fingerprinting</a>, which could be locked down to a degree where, unless the user <em>explicitly requests</em> for the browser to <em>authoritatively vet and verify</em> that a page is safe, the request is denied. (This notion of having domains - or even specific scripts! - be verified for safety is an interesting one, and one that I’ll probably start a new thread for in a minute.)</p>
          </div>
        </div>
      </div>

      <div class="post_container">
        <div class="avatar_container">
          <img src="../../../images/658_2.png" class="avatar" />
        </div>
        <div class="post">
          <div class="user_name">AshleyScirra</div>
          <div class="creation_date">2015-08-07</div>
          <div class="post_content">
<p>This seems to me to simply be a way to circumvent CORS restrictions, and therefore allow the security issues it seeks to prevent. I don’t see how the UA has any hope of identifying suspicion, since all it sees is arrays of pixels from various domains.</p>
          </div>
        </div>
      </div>


    </div>
  </body>
</html>
